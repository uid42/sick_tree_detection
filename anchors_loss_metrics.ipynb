{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "#from exp import nb_bbox_hw_statistics\n",
    "from detect_symbol.exp import nb_databunch\n",
    "from detect_symbol.exp import nb_resnet_ssd\n",
    "from detect_symbol.exp import nb_init_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from IPython.core import debugger as idb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**怎样设置anchor？**  \n",
    "  \n",
    "- 在detet_symbol项目中，我们对数据的统计特征比较清晰，也可以确定测试数据与训练数据的统计特征比较一致。所以可以根据训练数据的统计特征来确定anchor设置，而不用过于担心泛化问题。\n",
    "- 据此，关于anchor的设置可根据 bbox_hw_statistics.ipynb 的分析来确定，此处不赘述。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 无zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**怎样设置grid？**  \n",
    "  \n",
    "1. 根据 bbox_hw_statistics.ipynb 的分析，x方向上的最近距离是52.5，y方向上的最近距离是22. 但在模型的设计中，各层（卷积、池化）的 kernel_size 和 stride 等都在两个方向上一致，所以特征图的 stride 在两个方向应是一样的。所以应取更严格的条件，即特征图的stride（在x和y方向上都）应小于22.\n",
    "2. 特征图的stride一般都是 $2^n$ 的形式，又其应小于22，所以我们可以取最小 stride=16.\n",
    "3. 利用 receptive_field.ipynb 分析模型各层特征图的几何信息，并据此选择由哪些特征层来预测，以及各层负责哪些 anchor. 我们以resnet18为例。\n",
    "    1. 其 `layer3.1.conv2` 层 stride=16，receptive=211. 我们选择由该层负责（17,22）、（36,22）、（17,43）、（36,43）四个 anchor. 则 anchor 最大尺寸 43 约占 receptive=211 的 1/5.\n",
    "    2. 其 `layer4.1.conv2` 层 stride=32, receptive=435. 我们选择由该层负责（77,43）、（36,83）、（77,83）三个 anchor. 其 anchor 最大尺寸 83 同样约占 receptive=435 的 1/5.\n",
    "    3. 虽然 resnet18 没有更深的层，但是我们可以自己继续添加。假如添加至 `layer5.1.conv2` 层，其 stride=64，receptive 应约为 900，我们可以由该层负责（162,83）、（77,161）、（162,161）三个 anchor. 其 anchor 最大尺寸 162 也是约占 receptive=900 的 1/5.\n",
    "4. 因为我们已经确定了特征图的stride，则特征图的尺寸就由输入图片尺寸来决定。\n",
    "    - 特征图尺寸通常选择奇数，这样中心位置处恰有一个grid负责。\n",
    "    - 还要注意，在我们的detect_symbol项目中，训练图片尺寸不能太小。因为我们是从少量几张大图纸中随机截取大量小图片作为训练数据，而且若所截取图片中的目标不完整则抹掉该目标，所以截取的图片越小，则它能包含大目标（根据 bbox_hw_statistics.ipynb 的统计，最大目标尺寸约235）的概率就越小。\n",
    "    - 据此考虑，我们选择三个特征图尺寸分别为49、25、13. 则输入图片尺寸应为 49x16=784. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zoom [0.5,2], (20200426)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**怎样设置grid？**  \n",
    "  \n",
    "1. 根据 bbox_hw_statistics.ipynb 的分析，x方向上的最近距离是25，y方向上的最近距离是10.5. 但在模型的设计中，各层（卷积、池化）的 kernel_size 和 stride 等都在两个方向上一致，所以特征图的 stride 在两个方向应是一样的。所以应取更严格的条件，即特征图的stride（在x和y方向上都）应小于10.5.\n",
    "2. 特征图的stride一般都是 $2^n$ 的形式，又其应小于10.5，所以我们可以取最小 stride=8. \n",
    "3. 利用 receptive_field.ipynb 分析模型各层特征图的几何信息，并据此选择由哪些特征层来预测，以及各层负责哪些 anchor. 我们以resnet18为例。\n",
    "    1. 其 `layer2.1.conv2` 层 stride=8，receptive=99. 我们选择由该层负责（10,13）、(10,34)、（30,13）、（30,34）四个 anchor. 则 anchor 最大尺寸 34 约占 receptive=99 的 1/3.\n",
    "    2. 其 `layer3.1.conv2` 层 stride=16, receptive=211. 我们选择由该层负责（10,92）、（30,92）、（87,92）、(87,13)、(87,34)五个 anchor. 其 anchor 最大尺寸 92 同样约占 receptive=211 的 1/2.\n",
    "    3. 其 `layer4.1.conv2` 层 stride=32, receptive=435. 我们选择由该层负责（30,244）、（87,244）、（254,244）、（254,35）、（254,92）五个 anchor. 其 anchor 最大尺寸 244 同样约占 receptive=435 的 1/2.\n",
    "4. 因为我们已经确定了特征图的stride，则特征图的尺寸就由输入图片尺寸来决定。\n",
    "    - 特征图尺寸通常选择奇数，这样中心位置处恰有一个grid负责。\n",
    "    - 还要注意，在我们的detect_symbol项目中，训练图片尺寸不能太小。因为我们是从少量几张大图纸中随机截取大量小图片作为训练数据，而且若所截取图片中的目标不完整则抹掉该目标，所以截取的图片越小，则它能包含大目标（根据 bbox_hw_statistics.ipynb 的统计，最大目标尺寸约235）的概率就越小。\n",
    "    - 据此考虑，我们选择三个特征图尺寸分别为97、49、25. 则输入图片尺寸应为 97x8=776. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20200429"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**怎样设置grid？**  \n",
    "  \n",
    "1. 根据 bbox_hw_statistics.ipynb 的分析，x方向上的最近距离是25，y方向上的最近距离是10.5. 但在模型的设计中，各层（卷积、池化）的 kernel_size 和 stride 等都在两个方向上一致，所以特征图的 stride 在两个方向应是一样的。所以应取更严格的条件，即特征图的stride（在x和y方向上都）应小于10.5.\n",
    "2. 特征图的stride一般都是 $2^n$ 的形式，又其应小于10.5，所以我们可以取最小 stride=8. \n",
    "3. 利用 receptive_field.ipynb 分析模型各层特征图的几何信息，并据此选择由哪些特征层来预测，以及各层负责哪些 anchor. 我们以resnet34为例。\n",
    "    1. 其 `layer2.3.conv2` 层 stride=8，receptive=179. 我们选择由该层负责（10,13）、(10,34)、（30,13）、（30,34）四个 anchor. 则 anchor 最大尺寸 34 约占 receptive=179 的 1/5.3.\n",
    "    2. 其 `layer3.5.conv2` 层 stride=16, receptive=547. 我们选择由该层负责（10,92）、（30,92）、（87,92）、(87,13)、(87,34)五个 anchor. 其 anchor 最大尺寸 92 同样约占 receptive=547 的 1/5.9.\n",
    "    3. 其 `layer4.2.conv2` 层 stride=32, receptive=899. 我们选择由该层负责（30,244）、（87,244）、（254,244）、（254,35）、（254,92）五个 anchor. 其 anchor 最大尺寸 254 同样约占 receptive=899 的 1/3.5.\n",
    "4. 因为我们已经确定了特征图的stride，则特征图的尺寸就由输入图片尺寸来决定。\n",
    "    - 特征图尺寸通常选择奇数，这样中心位置处恰有一个grid负责。\n",
    "    - 还要注意，在我们的detect_symbol项目中，训练图片尺寸不能太小。因为我们是从少量几张大图纸中随机截取大量小图片作为训练数据，而且若所截取图片中的目标不完整则抹掉该目标，所以截取的图片越小，则它能包含大目标（根据 bbox_hw_statistics.ipynb 的统计，最大目标尺寸约235）的概率就越小。\n",
    "    - 据此考虑，我们选择三个特征图尺寸分别为97、49、25. 则输入图片尺寸应为 97x8=776. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_grids_anchors(fig_hw, grids, anchors):\n",
    "    import pdb; pdb.set_trace()\n",
    "    fig_h,fig_w = fig_hw\n",
    "    anchors = [[(ah/fig_h, aw/fig_w) for (ah,aw) in ancs] for ancs in anchors]\n",
    "    gridCnrs_ancCnrs = tensor([[x/gx, y/gy, (x+1)/gx, (y+1)/gy,\n",
    "                                -ax/2, -ay/2, ax/2, ay/2]\n",
    "                                for (gx,gy),ancs in zip(grids,anchors)\n",
    "                                for y in range(gy)\n",
    "                                for x in range(gx)\n",
    "                                for ax,ay in ancs])\n",
    "    \n",
    "    # grid corners, (use v to represent corners)\n",
    "    gvs = gridCnrs_ancCnrs[:,:4]\n",
    "    \n",
    "    # grid heights and widths\n",
    "    ghs = gvs[:,2] - gvs[:,0]\n",
    "    gws = gvs[:,3] - gvs[:,1]\n",
    "    \n",
    "    # anchor corners\n",
    "    avs = gridCnrs_ancCnrs[:,4:]\n",
    "    \n",
    "    # anchor heights and widthds\n",
    "    ahs = avs[:,2] - avs[:,0]\n",
    "    aws = avs[:,3] - avs[:,1]\n",
    "    \n",
    "    return gvs,ghs,gws,avs,ahs,aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 0, 49, 49, 22, 17), (24, 1, 49, 49, 22, 17), (25, 0, 49, 49, 22, 17), (25, 1, 49, 49, 22, 17), (26, 0, 49, 49, 22, 17), (26, 1, 49, 49, 22, 17)] 25 0 49 49 22 17\n",
      "r [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303]\n",
      "[24, 0, 49, 49, 22, 17]\n",
      "[24, 0, 49, 49, 22, 37]\n",
      "[24, 0, 49, 49, 43, 17]\n",
      "[24, 0, 49, 49, 43, 37]\n",
      "[25, 0, 49, 49, 22, 17]\n",
      "[25, 0, 49, 49, 22, 37]\n",
      "[25, 0, 49, 49, 43, 17]\n",
      "[25, 0, 49, 49, 43, 37]\n",
      "[26, 0, 49, 49, 22, 17]\n",
      "[26, 0, 49, 49, 22, 37]\n",
      "[26, 0, 49, 49, 43, 17]\n",
      "[26, 0, 49, 49, 43, 37]\n",
      "[24, 1, 49, 49, 22, 17]\n",
      "[24, 1, 49, 49, 22, 37]\n",
      "[24, 1, 49, 49, 43, 17]\n",
      "[24, 1, 49, 49, 43, 37]\n",
      "[25, 1, 49, 49, 22, 17]\n",
      "[25, 1, 49, 49, 22, 37]\n",
      "[25, 1, 49, 49, 43, 17]\n",
      "[25, 1, 49, 49, 43, 37]\n",
      "[26, 1, 49, 49, 22, 17]\n",
      "[26, 1, 49, 49, 22, 37]\n",
      "[26, 1, 49, 49, 43, 17]\n",
      "[26, 1, 49, 49, 43, 37]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取某个idx的anchor的周围anchor的idx列表。距离默认1\n",
    "#排列方式是先y后x，每个xy重复一下anchors的数量\n",
    "def find_neibs(idx, fig_hw, grids, anchors, dis = 1):\n",
    "    fig_h,fig_w = fig_hw\n",
    "    #anchors = [[(ah/fig_h, aw/fig_w) for (ah,aw) in ancs] for ancs in anchors]\n",
    "    #直接按照get_grids_anchors生成的方式生成一遍每个对应的xy坐标和所在grid就行了。\n",
    "    gridCnrs_ancCnrs = [[x, y, gx, gy, ax, ay]\n",
    "                                for (gx,gy),ancs in zip(grids,anchors)\n",
    "                                for y in range(gy)\n",
    "                                for x in range(gx)\n",
    "                                for ax,ay in ancs]\n",
    "    assert idx < len(gridCnrs_ancCnrs)\n",
    "    x, y, gx, gy, ax, ay = gridCnrs_ancCnrs[idx]\n",
    "    neibs = [(nx, ny, gx, gy, ax, ay) for nx in range(x - dis, x + dis + 1) \n",
    "                         for ny in range(y - dis, y + dis + 1) \n",
    "                             if nx >= 0 and ny >= 0]\n",
    "    print(neibs, x, y, gx, gy, ax, ay)\n",
    "    ret = []\n",
    "    for i in range(len(gridCnrs_ancCnrs)):\n",
    "        x, y, gx, gy, ax, ay = gridCnrs_ancCnrs[i]\n",
    "        for n in neibs:\n",
    "            if n[0] == x and n[1] == y and n[2] == gx and n[3] == gy:#[x, y, gx, gy, ax, ay]:\n",
    "                #if operator.eq(n, neibs):\n",
    "                ret += [i]\n",
    "    print('r', ret)\n",
    "    for r in ret:\n",
    "        print(gridCnrs_ancCnrs[r])\n",
    "    return ret\n",
    "    \n",
    "fig_hw = (784,784)\n",
    "grids = [(49,49),(25,25),(13,13)]\n",
    "anchors = [[(22,17),(22,37),(43,17),(43,37)],\n",
    "           [(43,77),(83,37),(83,77)],\n",
    "           [(83,162),(162,77),(162,162)]]\n",
    "find_neibs(100, fig_hw, grids, anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-b13624ddaa14>(4)get_grids_anchors()\n",
      "-> fig_h,fig_w = fig_hw\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "#距离之间的事情可以不考虑？先按照resnet18来一个\n",
    "# 获取 grids 和 anchors\n",
    "gvs,ghs,gws,avs,ahs,aws = get_grids_anchors(fig_hw = (776,776),\n",
    "                                            grids = [(49,49)],\n",
    "                                            anchors = [[(22,17)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_hw = (784,784)\n",
    "# grids = [(49,49),(25,25),(13,13)]\n",
    "# anchors = [[(22,17),(22,37),(43,17),(43,37)],\n",
    "#                                          [(43,77),(83,37),(83,77)],\n",
    "#                                          [(83,162),(162,77),(162,162)]]\n",
    "#for (gx,gy),ancs in zip(grids,anchors) : \n",
    "#        print(gx,gy,ancs)\n",
    "        \n",
    "#at = [[gx, gy, ancs, y, x]  for (gx,gy),ancs in zip(grids,anchors) for y in range(gy) for x in range(gx)]    \n",
    "#print(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2401, 4]),\n",
       " torch.Size([2401]),\n",
       " torch.Size([2401]),\n",
       " torch.Size([2401, 4]),\n",
       " torch.Size([2401]),\n",
       " torch.Size([2401]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这些变量的尺寸\n",
    "gvs.shape, ghs.shape, gws.shape, avs.shape, ahs.shape, aws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为什么有这样的尺寸\n",
    "#49*49*4+25*25*3+13*13*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2401"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49*49*1  #只有一个anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zip as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 此函数仅为方便其它测试的调用\n",
    "# def get_ga433():\n",
    "#     return get_grids_anchors(fig_hw = (784,784),\n",
    "#                               grids = [(49,49),(25,25),(13,13)],\n",
    "#                               anchors = [[(22,17),(22,37),(43,17),(43,37)],\n",
    "#                                          [(43,77),(83,37),(83,77)],\n",
    "#                                          [(83,162),(162,77),(162,162)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_ga444():\n",
    "#     return get_grids_anchors(fig_hw = (784,784),\n",
    "#                               grids = [(49,49),(25,25),(13,13)],\n",
    "#                               anchors = [[(22,17),(22,37),(43,17),(43,37)],\n",
    "#                                          [(43,37),(43,77),(83,37),(83,77)],\n",
    "#                                          [(83,77),(83,162),(162,77),(162,162)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_ga666():\n",
    "#     return get_grids_anchors(fig_hw = (776,776),\n",
    "#                               grids = [(97,97),(49,49),(25,25)],\n",
    "#                               anchors = [[( 34, 3),( 34,10),( 34, 30),(13, 30),( 5, 30),(13,10)],\n",
    "#                                          [( 92,10),( 92,30),( 92, 87),(35, 87),(13, 87),(34,30)],\n",
    "#                                          [(244,30),(244,87),(244,254),(92,254),(35,254),(92,87)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_ga1():\n",
    "    return get_grids_anchors(fig_hw = (776,776), grids = [(49,49)]\n",
    "                             , anchors = [[(1,1)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_getIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test_ahws = [(22,17),(22,37),(43,17),(43,37),\n",
    "             (43,77),(83,37),(83,77),\n",
    "             (83,162),(162,77),(162,162)]\n",
    "test_ahs = tensor([a[0]/784 for a in test_ahws])\n",
    "test_aws = tensor([a[1]/784 for a in test_ahws])\n",
    "test_abbs = tensor([[-ah/2,-aw/2,ah/2,aw/2] for (ah,aw) in zip(test_ahs,test_aws)])\n",
    "\n",
    "def test_getIdx(bb):\n",
    "    # bb中心\n",
    "    cx = bb[[0,2]].mean()\n",
    "    cy = bb[[1,3]].mean()\n",
    "     \n",
    "    # bb去中心偏移\n",
    "    bb[[0,2]] = bb[[0,2]] - cx\n",
    "    bb[[1,3]] = bb[[1,3]] - cy\n",
    "    \n",
    "    scores = iou(bb[None],test_abbs)\n",
    "    idxa = scores.max(0)[1] # idxa: index of anchor\n",
    "    \n",
    "    if idxa in [0,1,2,3]: \n",
    "        offset = 0\n",
    "        nanc = 4\n",
    "        g = 49\n",
    "    elif idxa in [4,5,6]: \n",
    "        offset = 49*49*4\n",
    "        idxa -= 4\n",
    "        nanc = 3\n",
    "        g = 25\n",
    "    elif idxa in [7,8,9]: \n",
    "        offset = 49*49*4 + 25*25*3\n",
    "        idxa -= 7\n",
    "        nanc = 3\n",
    "        g = 13\n",
    "\n",
    "    idxx = int(cx*g)\n",
    "    idxy = int(cy*g)\n",
    "    idx = offset + (idxy*g+idxx)*nanc+idxa\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox $\\leftrightarrow$ prediction: b2t, t2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b_x=\\hat{\\sigma}\\left(t_x\\right)\\cdot g_w+c_x$  \n",
    "$b_y=\\hat{\\sigma}\\left(t_y\\right)\\cdot g_h+c_y$  \n",
    "$b_h=p_h\\cdot e^{t_h}$  \n",
    "$b_w=p_w\\cdot e^{t_w}$  \n",
    "\n",
    "\n",
    "where:  \n",
    "- $\\hat{\\sigma}=(1+\\epsilon)\\cdot(\\sigma-0.5)+0.5$，and $\\epsilon$ is a small positive number.\n",
    "- $t_x,t_y,t_w,t_h$ are predictions made by model.  \n",
    "- $c_x,c_y$ is the top left corner of the grid cell of the anchor.  \n",
    "- $g_h,g_w$ are the height and width of the grid cell.\n",
    "- $p_h,p_w$ are the height and width of the anchor.\n",
    "- $c_x,c_y,p_h,p_w,g_h,g_w$ are normalized by the image height and width.\n",
    "- $b_x,b_y,b_w,b_h$ are the center x and y, the width and height of predicted boundary box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面绘出 $\\hat{\\sigma}$ 曲线："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f77ae1e11d0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 hat{sigma}\n",
    "eta = 1\n",
    "\n",
    "xxx = tensor(range(-100,100)).float()/10\n",
    "yyy = (1+eta)*(torch.sigmoid(xxx)-0.5) + 0.5\n",
    "\n",
    "plt.plot(xxx,yyy);\n",
    "plt.plot(xxx,torch.zeros(len(xxx)),'k--',linewidth=1);\n",
    "plt.plot(xxx,torch.zeros(len(xxx))+1,'k--',linewidth=1);\n",
    "plt.plot(torch.zeros(len(yyy)),yyy,'k--',linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def t2b(t,idx,eps=1):\n",
    "    cx,cy = gvs[idx,0],gvs[idx,1]\n",
    "    gh,gw = ghs[idx],gws[idx]\n",
    "    ph,pw = ahs[idx],aws[idx]\n",
    "    \n",
    "    sig_tx = torch.sigmoid(t[:,0])\n",
    "    sig_ty = torch.sigmoid(t[:,1])\n",
    "    exp_th = torch.exp(t[:,2])\n",
    "    exp_tw = torch.exp(t[:,3])\n",
    "    \n",
    "    hatsig_tx = (1+eps)*(sig_tx-0.5) + 0.5\n",
    "    hatsig_ty = (1+eps)*(sig_ty-0.5) + 0.5\n",
    "    \n",
    "    bx = hatsig_tx*gw + cx # x of center of box\n",
    "    by = hatsig_ty*gh + cy # y of center of box\n",
    "    \n",
    "    bh = ph * exp_th    # height of box\n",
    "    bw = pw * exp_tw    # width of box\n",
    "    \n",
    "    tl_x = bx - bh/2 # x of top-left corner of box\n",
    "    tl_y = by - bw/2 # y of top-left corner of box \n",
    "    br_x = bx + bh/2 # x of bottom-right corner of box\n",
    "    br_y = by + bw/2 # y of bottom-right corner of box\n",
    "    \n",
    "    return torch.stack([tl_x, tl_y, br_x, br_y]).t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### b2t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**math of b2t:**  \n",
    "  \n",
    "$\\hat{\\sigma}(t_x)=(b_x-c_x)/g_h$  \n",
    "$\\hat{\\sigma}(t_y)=(b_y-c_y)/g_w$   \n",
    "$e^{t_x}=b_h/p_h$  \n",
    "$e^{t_y}=b_w/p_w$  \n",
    "  \n",
    "$\\sigma(t_x)=\\frac{\\hat{\\sigma}(t_x)-0.5}{1+\\epsilon}+0.5=\\frac{\\hat{\\sigma}(t_x)-0.5+0.5+0.5\\cdot\\epsilon}{1+\\epsilon}=\\frac{\\hat{\\sigma}(t_x)+0.5\\cdot\\epsilon}{1+\\epsilon}$  \n",
    "$\\sigma(t_y)=\\frac{\\hat{\\sigma}(t_y)-0.5}{1+\\epsilon}+0.5=\\frac{\\hat{\\sigma}(t_y)-0.5+0.5+0.5\\cdot\\epsilon}{1+\\epsilon}=\\frac{\\hat{\\sigma}(t_y)+0.5\\cdot\\epsilon}{1+\\epsilon}$  \n",
    "  \n",
    "$\\sigma(t_x)=\\frac{1}{1+e^{-t_x}}\\Rightarrow e^{-t_x}=\\frac{1}{\\sigma(t_x)}-1=\\frac{1-\\sigma(t_x)}{\\sigma(t_x)}\\Rightarrow e^{t_x}=\\frac{\\sigma(t_x)}{1-\\sigma(t_x)}\\Rightarrow$    \n",
    "  \n",
    "$t_x=\\log(\\frac{\\sigma(t_x)}{1-\\sigma(t_x)})$  \n",
    "$t_y=\\log(\\frac{\\sigma(t_y)}{1-\\sigma(t_y)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def b2t(b,idx,eps=1):\n",
    "    cx,cy = gvs[idx,0],gvs[idx,1]\n",
    "    gh,gw = ghs[idx],gws[idx]\n",
    "    ph,pw = ahs[idx],aws[idx]\n",
    "    \n",
    "    bx = (b[:,0] + b[:,2])/2 # x of center of box\n",
    "    by = (b[:,1] + b[:,3])/2 # y of center of box\n",
    "    bh = b[:,2] - b[:,0]     # height of box\n",
    "    bw = b[:,3] - b[:,1]     # width of box\n",
    "    \n",
    "    hatsig_tx = (bx - cx)/gh\n",
    "    hatsig_ty = (by - cy)/gw\n",
    "    exp_th = bh / ph\n",
    "    exp_tw = bw / pw\n",
    "    \n",
    "    sig_tx = (hatsig_tx+0.5*eps)/(1+eps)\n",
    "    sig_ty = (hatsig_ty+0.5*eps)/(1+eps)\n",
    "    \n",
    "    tx = torch.log(sig_tx/(1-sig_tx))\n",
    "    ty = torch.log(sig_ty/(1-sig_ty))\n",
    "    th = torch.log(exp_th)\n",
    "    tw = torch.log(exp_tw)\n",
    "    \n",
    "    return torch.stack([tx, ty, th, tw]).t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox $\\leftrightarrow$ cent, h, w: bbox2chw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def bbox2chw(b):\n",
    "    '''\n",
    "    将bbox的（左上x，左上y，右下x，右下y）表示变为（中心x，中心y，高，宽）表示\n",
    "    '''\n",
    "    cx = b[...,[0,2]].mean(-1)[...,None]\n",
    "    cy = b[...,[1,3]].mean(-1)[...,None]\n",
    "    \n",
    "    h = (b[...,2]-b[:,0])[...,None]\n",
    "    w = (b[...,3]-b[:,1])[...,None]\n",
    "    \n",
    "    return torch.cat([cx,cy,h,w],dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_y(bboxs):\n",
    "    bboxs = bboxs.view(-1,4)\n",
    "    keep = bboxs.abs().sum(-1).nonzero()[:,0]\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def intersect(box_a, box_b):\n",
    "    max_xy = torch.min(box_a[..., 2:], box_b[..., 2:])\n",
    "    min_xy = torch.max(box_a[..., :2], box_b[..., :2])\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[..., 0] * inter[..., 1]\n",
    "\n",
    "def box_sz(b): return ((b[..., 2]-b[..., 0]) * (b[..., 3]-b[..., 1]))\n",
    "\n",
    "def iou(box_a, box_b):\n",
    "    inter = intersect(box_a, box_b)\n",
    "    union = box_sz(box_a) + box_sz(box_b) - inter\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_scores_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_scores_hits(gt_bboxs): \n",
    "    # ground truch bbox center x,y\n",
    "    gt_cx = gt_bboxs[:,[0,2]].mean(-1)\n",
    "    gt_cy = gt_bboxs[:,[1,3]].mean(-1)\n",
    "    \n",
    "    # find the center where the anchors will be shifted at.    \n",
    "    anc_cx = (gt_cx[:,None]<gvs[:,0]).float() * (gvs[:,0]-gt_cx[:,None]) + \\\n",
    "             (gt_cx[:,None]>gvs[:,2]).float() * (gvs[:,2]-gt_cx[:,None]) + \\\n",
    "              gt_cx[:,None];\n",
    "    anc_cy = (gt_cy[:,None]<gvs[:,1]).float() * (gvs[:,1]-gt_cy[:,None]) + \\\n",
    "             (gt_cy[:,None]>gvs[:,3]).float() * (gvs[:,3]-gt_cy[:,None]) + \\\n",
    "              gt_cy[:,None];\n",
    "\n",
    "    # shift anchors at center (anc_cx, anc_cy)\n",
    "    # fxdAncCnrs: fixed anchor corners\n",
    "    fxdAncVs = avs + torch.cat([anc_cx[...,None], anc_cy[...,None]],dim=-1).repeat(1,1,2)\n",
    "\n",
    "    # 匹配度得分\n",
    "    scores = iou(gt_bboxs[:,None,:], fxdAncVs)\n",
    "    \n",
    "    # 判断目标bbox的中心落在哪个cell内\n",
    "    hits = ((gt_cx[:,None] >= gvs[:,0][None]) &\n",
    "            (gt_cx[:,None] <  gvs[:,2][None]) &\n",
    "            (gt_cy[:,None] >= gvs[:,1][None]) &\n",
    "            (gt_cy[:,None] <  gvs[:,3][None]))\n",
    "\n",
    "    return scores,hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idx_fromScoresHits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def idx_fromScoresHits(scores,hits):\n",
    "    idx = (scores*hits.float()).max(1)[1]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_clasWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_clasWeights(clas_cnts=[], max_imblance=5):\n",
    "    if max_imblance<=1: \n",
    "        max_imblance = 1.01\n",
    "    \n",
    "    clas_cnts = np.array(clas_cnts)\n",
    "    N = len(clas_cnts)\n",
    "    minCnt = min(clas_cnts)\n",
    "    maxCnt = max(clas_cnts)\n",
    "    \n",
    "    eta = (maxCnt-minCnt*max_imblance)/(max_imblance-1)\n",
    "    eta = max(eta,0)\n",
    "    \n",
    "    expect_cnts = clas_cnts + eta\n",
    "    weights = expect_cnts/clas_cnts\n",
    "    weights = weights * N / weights.sum()\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**若某anchor对某object负责，则应训练其classification靠近该object的类别。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def clas_L(pred_batch, *gt_batch, lambda_clas=1, clas_weights=None, gaf):\n",
    "    loss = 0\n",
    "    cnt = 0\n",
    "    for pred_clas,gt_bboxs,gt_clas in zip(pred_batch[2], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "        \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_clas = gt_clas[keep]\n",
    "        \n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        gt_clas = gt_clas - 1 # the databunch add a 'background' class to classes[0], but we don't want that,so gt_clas-1\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        pred_clas = pred_clas[idx]\n",
    "        \n",
    "        loss += F.cross_entropy(pred_clas, gt_clas, weight=clas_weights, reduction='sum')\n",
    "        cnt += gt_clas.shape[0]\n",
    "        \n",
    "    return lambda_clas*loss/cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox center loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**若某 anchor 对某 object 负责，则应训练其预测之 中心 靠近该 object box 之 中心。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cent_L(pred_batch, *gt_batch, lambda_cent=1, clas_weights=None, gaf):\n",
    "    loss = 0\n",
    "    cnt = 0\n",
    "    for pred_txy,gt_bboxs,gt_clas in zip(pred_batch[0], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "          \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_clas = gt_clas[keep]\n",
    "        \n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        gt_clas = gt_clas - 1\n",
    "        \n",
    "        if clas_weights is not None: ws = clas_weights[gt_clas]\n",
    "        else: ws = None\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        gt_t = gaf.b2t(gt_bboxs,idx,eps=1)\n",
    "        pred_txy = pred_txy[idx]\n",
    "        \n",
    "        if ws is not None:\n",
    "            tmp = ((gt_t[...,:2]-pred_txy)*ws[...,None]).abs().sum()\n",
    "        else:\n",
    "            tmp = (gt_t[...,:2]-pred_txy).abs().sum()\n",
    "        \n",
    "        loss += tmp\n",
    "        cnt += len(idx)\n",
    "    \n",
    "    return lambda_cent*loss/cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### positive confidence loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**若某 anchor 为某 object 负责，则训练其 conf_score 靠近 1。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def pConf_L(pred_batch, *gt_batch, lambda_pconf=1, clas_weights=None, gaf):\n",
    "    loss = 0\n",
    "    cnt = 0\n",
    "    for pred_conf,gt_bboxs,gt_clas in zip(pred_batch[1], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "          \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_clas = gt_clas[keep]\n",
    "        \n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        gt_clas = gt_clas - 1\n",
    "        \n",
    "        if clas_weights is not None: ws = clas_weights[gt_clas]\n",
    "        else: ws = None\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        conf_pos = pred_conf[idx]\n",
    "#         conf_pos = torch.sigmoid(conf_pos)\n",
    "#         tmp = (1-conf_pos).abs().sum()\n",
    "        if ws is not None: \n",
    "            tmp = F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),weight=ws[...,None],reduction='sum')\n",
    "        else: \n",
    "            tmp = F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),reduction='sum')\n",
    "    \n",
    "    \n",
    "        loss += tmp\n",
    "        cnt += len(idx)\n",
    "        \n",
    "    return lambda_pconf*loss/cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negative confidence loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**若某 anchor 不对任何 object 负责，且它与任何 object 的 匹配得分 都差于 threshold，则训练其 conf_score 靠近 0。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def nConf_L(pred_batch, *gt_batch, gaf, conf_th=0.5, lambda_nconf=1):\n",
    "    loss = 0\n",
    "    cnt = 0\n",
    "    for pred_conf,gt_bboxs,_ in zip(pred_batch[1], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "        \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        scores[range(0,len(idx)),idx] = conf_th + 1 # 强制责任anchor的得分好于threshold\n",
    "        tmp = scores>conf_th # 判断各得分是否好于threshold\n",
    "        tmp = tmp.max(dim=0)[0] # 各anchor是否有任意一个好于threshold的得分\n",
    "        neg_idx = torch.where(tmp==0)[0] # 如果没有，该anchor是negative anchor\n",
    "        \n",
    "        conf_neg = pred_conf[neg_idx]\n",
    "#         conf_neg = torch.sigmoid(conf_neg)\n",
    "#         loss += conf_neg.abs().sum()\n",
    "        tmp = F.binary_cross_entropy_with_logits(conf_neg,torch.zeros_like(conf_neg),reduction='sum')\n",
    "        loss += tmp\n",
    "        cnt += len(neg_idx)\n",
    "        \n",
    "    return lambda_nconf*loss/cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox height and width loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**若某 anchor 对某 object 负责，则应训练其预测之 高与宽 靠近该 object box 之 高与宽。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def hw_L(pred_batch, *gt_batch, gaf, lambda_hw=1, clas_weights=None):\n",
    "    loss = 0\n",
    "    cnt = 0\n",
    "    for pred_thw,gt_bboxs,gt_clas in zip(pred_batch[3], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "          \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_clas = gt_clas[keep]\n",
    "        \n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        gt_clas = gt_clas - 1\n",
    "        \n",
    "        if clas_weights is not None: ws = clas_weights[gt_clas]\n",
    "        else: ws = None\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        gt_t = gaf.b2t(gt_bboxs,idx,eps=1)\n",
    "        pred_thw = pred_thw[idx]\n",
    "        \n",
    "        if ws is not None: \n",
    "            tmp = ((gt_t[...,2:]-pred_thw)*ws[...,None]).abs().sum()\n",
    "        else: \n",
    "            tmp = (gt_t[...,2:]-pred_thw).abs().sum()\n",
    "\n",
    "        loss += tmp\n",
    "        cnt += len(idx)\n",
    "    \n",
    "    return lambda_hw*loss/cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def yolo_L(pred_batch, *gt_batch, conf_th=0.5,\n",
    "           lambda_cent=1, lambda_pconf=1, lambda_nconf=1, lambda_clas=1, lambda_hw=1, clas_weights=None, gaf):\n",
    "    '''\n",
    "    clas_weights: \n",
    "    为了解决数据集的imbalance问题，一种方法是在dataloader中使用WeightedRandomSampler，但是这种方法不适用于目标检测问题。\n",
    "    因为，（1）目标检测的label不是一个简单的数值（2）目标检测问题的一张图片可能包括不同类别的多个目标。\n",
    "    所以为了解决目标检测问题中的imbalance问题，我们的方法是在损失函数中使用权重。\n",
    "    为各类别分配权重，各目标对应的损失乘以该目标所属类别的权重。\n",
    "    默认为None，即不使用权重。\n",
    "    若设置非None，则clas_weights应该是一个一维tensor，其长度等于数据集的类别数。\n",
    "    若设置为全1，则相当于不使用权重。\n",
    "    合理的设置应保证所有元素之和等于数据集的类别数，否则相当于对损失函数的整体做了缩放。\n",
    "    '''\n",
    "    clas_loss = 0\n",
    "    cent_loss = 0\n",
    "    pconf_loss = 0\n",
    "    nconf_loss = 0\n",
    "    hw_loss = 0\n",
    "    pos_cnt = 0\n",
    "    neg_cnt = 0\n",
    "    \n",
    "    for pred_txy,pred_conf,pred_clas,pred_thw,gt_bboxs,gt_clas in zip(*pred_batch, *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "          \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_clas = gt_clas[keep]\n",
    "        \n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        gt_clas = gt_clas - 1 # the databunch add a 'background' class to classes[0], but we don't want that,so gt_clas-1\n",
    "        \n",
    "        if clas_weights is not None: ws = clas_weights[gt_clas]\n",
    "        else: ws = None\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        # classification loss\n",
    "        pred_clas = pred_clas[idx]\n",
    "        clas_loss += F.cross_entropy(pred_clas, gt_clas, weight=clas_weights, reduction='sum')\n",
    "        \n",
    "        # bbox center loss\n",
    "        gt_t = gaf.b2t(gt_bboxs,idx,eps=1)\n",
    "        pred_txy = pred_txy[idx]\n",
    "        if ws is not None:\n",
    "            cent_loss += ((gt_t[...,:2]-pred_txy)*ws[...,None]).abs().sum()\n",
    "        else:\n",
    "            cent_loss += (gt_t[...,:2]-pred_txy).abs().sum()\n",
    "        \n",
    "        # bbox height and width loss\n",
    "        pred_thw = pred_thw[idx]\n",
    "        if ws is not None: \n",
    "            hw_loss += ((gt_t[...,2:]-pred_thw)*ws[...,None]).abs().sum()\n",
    "        else: \n",
    "            hw_loss += (gt_t[...,2:]-pred_thw).abs().sum()\n",
    "        \n",
    "        # positive confidence loss\n",
    "        conf_pos = pred_conf[idx]\n",
    "        if ws is not None: \n",
    "            pconf_loss += F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),weight=ws[...,None],reduction='sum')\n",
    "        else: \n",
    "            pconf_loss += F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),reduction='sum')\n",
    "        \n",
    "        # negative conficence loss\n",
    "        scores[range(0,len(idx)),idx] = conf_th + 1 # 强制责任anchor的得分好于threshold\n",
    "        tmp = scores>conf_th # 判断各得分是否好于threshold\n",
    "        tmp = tmp.max(dim=0)[0] # 各anchor是否有任意一个好于threshold的得分\n",
    "        neg_idx = torch.where(tmp==0)[0] # 如果没有，该anchor是negative anchor\n",
    "        conf_neg = pred_conf[negn_idx]\n",
    "        nconf_loss += F.binary_cross_entropy_with_logits(conf_neg,torch.zeros_like(conf_neg),reduction='sum')\n",
    "        \n",
    "        pos_cnt += len(idx)\n",
    "        neg_cnt += len(neg_idx)\n",
    "        \n",
    "    clas_loss  = lambda_clas  * clas_loss  /pos_cnt\n",
    "    cent_loss  = lambda_cent  * cent_loss  /pos_cnt\n",
    "    pconf_loss = lambda_pconf * pconf_loss /pos_cnt\n",
    "    nconf_loss = lambda_nconf * nconf_loss /neg_cnt\n",
    "    hw_loss    = lambda_hw    * hw_loss   /pos_cnt\n",
    "    \n",
    "    return clas_loss + cent_loss + pconf_loss + nconf_loss + hw_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridAnchor_Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     44,
     69
    ]
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class GridAnchor_Funcs():\n",
    "    def __init__(self,gvs,avs,device):\n",
    "        '''\n",
    "        基于grid和anchor的函数，这些函数都需要访问grid和anchor数据，因此构造一个类，把grid和anchor数据跟这些函数绑在一起。\n",
    "        参数：\n",
    "        -- gvs: grid corner coordinates, tensor([[min_x0,min_y0,max_x0,max_y0],[min_x1,min_y1,max_x1,max_y1],...])的形式\n",
    "        -- avs: anchor corner coordinates, tensor([[min_x0,min_y0,max_x0,max_y0],[min_x1,min_y1,max_x1,max_y1],...])的形式\n",
    "        -- device: a torch.device object\n",
    "        '''\n",
    "        self.gvs = gvs.to(device)\n",
    "        self.avs = avs.to(device)\n",
    "        \n",
    "        self.ghs = self.gvs[...,2] - self.gvs[...,0] # gh: grid height\n",
    "        self.gws = self.gvs[...,3] - self.gvs[...,1] # gw: grid width\n",
    "        self.ahs = self.avs[...,2] - self.avs[...,0] # ah: anchor height\n",
    "        self.aws = self.avs[...,3] - self.avs[...,1] # aw: anchor width\n",
    "        \n",
    "    def t2b(self,t,idx,eps=1):\n",
    "        cx,cy = self.gvs[idx,0],self.gvs[idx,1]\n",
    "        gh,gw = self.ghs[idx],self.gws[idx]\n",
    "        ph,pw = self.ahs[idx],self.aws[idx]\n",
    "\n",
    "        sig_tx = torch.sigmoid(t[...,0])\n",
    "        sig_ty = torch.sigmoid(t[...,1])\n",
    "        exp_th = torch.exp(t[...,2])\n",
    "        exp_tw = torch.exp(t[...,3])\n",
    "\n",
    "        hatsig_tx = (1+eps)*(sig_tx-0.5) + 0.5\n",
    "        hatsig_ty = (1+eps)*(sig_ty-0.5) + 0.5\n",
    "\n",
    "        bx = hatsig_tx*gw + cx # x of center of box\n",
    "        by = hatsig_ty*gh + cy # y of center of box\n",
    "\n",
    "        bh = ph * exp_th    # height of box\n",
    "        bw = pw * exp_tw    # width of box\n",
    "\n",
    "        tl_x = bx - bh/2 # x of top-left corner of box\n",
    "        tl_y = by - bw/2 # y of top-left corner of box \n",
    "        br_x = bx + bh/2 # x of bottom-right corner of box\n",
    "        br_y = by + bw/2 # y of bottom-right corner of box\n",
    "\n",
    "        res = torch.stack([tl_x, tl_y, br_x, br_y],dim=0)\n",
    "        res = res.permute(list(range(len(res.shape)))[1:]+[0])\n",
    "        return res\n",
    "    \n",
    "    def b2t(self, b,idx,eps=1):\n",
    "        cx,cy = self.gvs[idx,0],self.gvs[idx,1]\n",
    "        gh,gw = self.ghs[idx],self.gws[idx]\n",
    "        ph,pw = self.ahs[idx],self.aws[idx]\n",
    "\n",
    "        bx = (b[:,0] + b[:,2])/2 # x of center of box\n",
    "        by = (b[:,1] + b[:,3])/2 # y of center of box\n",
    "        bh = b[:,2] - b[:,0]     # height of box\n",
    "        bw = b[:,3] - b[:,1]     # width of box\n",
    "\n",
    "        hatsig_tx = (bx - cx)/gh\n",
    "        hatsig_ty = (by - cy)/gw\n",
    "        exp_th = bh / ph\n",
    "        exp_tw = bw / pw\n",
    "\n",
    "        sig_tx = (hatsig_tx+0.5*eps)/(1+eps)\n",
    "        sig_ty = (hatsig_ty+0.5*eps)/(1+eps)\n",
    "\n",
    "        tx = torch.log(sig_tx/(1-sig_tx))\n",
    "        ty = torch.log(sig_ty/(1-sig_ty))\n",
    "        th = torch.log(exp_th)\n",
    "        tw = torch.log(exp_tw)\n",
    "\n",
    "        return torch.stack([tx, ty, th, tw]).t()\n",
    "    \n",
    "    def get_scores_hits(self, gt_bboxs): \n",
    "        # ground truch bbox center x,y\n",
    "        gt_cx = gt_bboxs[:,[0,2]].mean(-1)\n",
    "        gt_cy = gt_bboxs[:,[1,3]].mean(-1)\n",
    "\n",
    "        # find the center where the anchors will be shifted at.    \n",
    "        anc_cx = (gt_cx[:,None]<self.gvs[:,0]).float() * (self.gvs[:,0]-gt_cx[:,None]) + \\\n",
    "                 (gt_cx[:,None]>self.gvs[:,2]).float() * (self.gvs[:,2]-gt_cx[:,None]) + \\\n",
    "                  gt_cx[:,None];\n",
    "        anc_cy = (gt_cy[:,None]<self.gvs[:,1]).float() * (self.gvs[:,1]-gt_cy[:,None]) + \\\n",
    "                 (gt_cy[:,None]>self.gvs[:,3]).float() * (self.gvs[:,3]-gt_cy[:,None]) + \\\n",
    "                  gt_cy[:,None];\n",
    "\n",
    "        # shift anchors at center (anc_cx, anc_cy)\n",
    "        # fxdAncCnrs: fixed anchor corners\n",
    "        fxdAncVs = self.avs + torch.cat([anc_cx[...,None], anc_cy[...,None]],dim=-1).repeat(1,1,2)\n",
    "\n",
    "        # 匹配度得分\n",
    "        scores = iou(gt_bboxs[:,None,:], fxdAncVs)\n",
    "\n",
    "        # 判断目标bbox的中心落在哪个cell内\n",
    "        hits = ((gt_cx[:,None] >= self.gvs[:,0][None]) &\n",
    "                (gt_cx[:,None] <  self.gvs[:,2][None]) &\n",
    "                (gt_cy[:,None] >= self.gvs[:,1][None]) &\n",
    "                (gt_cy[:,None] <  self.gvs[:,3][None]))\n",
    "\n",
    "        return scores,hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get databunch\n",
    "data = nb_databunch.get_databunch()\n",
    "x,y = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get model and load init parameters\n",
    "model = nb_resnet_ssd.get_resnet18_ssd()\n",
    "model.load_state_dict(torch.load('./models/resnet18_ssd_init.pth'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check the statistics of layer outputs\n",
    "nb_init_model.show_layer_stats(model,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pred a batch\n",
    "pred = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### find idx of the responsible anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 选择一个bbox\n",
    "samp = 11 # samp: sample, get one bbox from this sample\n",
    "bb = (y[0][samp][-1]+1)/2\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 测试 get_scores_hits 和 idx_fromScoresHits\n",
    "scores,hits=get_scores_hits(bb[None])\n",
    "idx = idx_fromScoresHits(scores,hits)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 用另一种方法与之对照验证\n",
    "test_idx = test_getIdx(bb.clone())\n",
    "test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert idx.item()==test_idx.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get GridAnchor_Funcs object\n",
    "gvs,_,_,avs,_,_ = get_ga433()\n",
    "gaf = GridAnchor_Funcs(gvs,avs,torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 设置一个简单的clas_weights，你可以更改它的值来试验\n",
    "clas_weights = torch.ones(16)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification loss\n",
    "clas_loss = clas_L(pred,*y,gaf=gaf, clas_weights=clas_weights)\n",
    "clas_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bbox center loss\n",
    "cent_loss = cent_L(pred,*y,gaf=gaf, clas_weights=clas_weights)\n",
    "cent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# positive confidence loss\n",
    "pconf_loss = pConf_L(pred,*y,gaf=gaf, clas_weights=clas_weights)\n",
    "pconf_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# negative confidence loss\n",
    "nconf_loss = nConf_L(pred,*y,gaf=gaf)\n",
    "nconf_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bbox height and width loss\n",
    "hw_loss = hw_L(pred,*y,gaf=gaf, clas_weights=clas_weights)\n",
    "hw_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# total loss\n",
    "total_loss = yolo_L(pred,*y, clas_weights=clas_weights,gaf=gaf)\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert (clas_loss+cent_loss+pconf_loss+hw_loss+nconf_loss)==total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def clas_acc(pred_batch, *gt_batch, gaf):\n",
    "    posCnt = tensor(0.)\n",
    "    totCnt = tensor(0.)\n",
    "    for pred_clas,gt_bboxs,gt_clas in zip(pred_batch[2], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "        \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_clas = gt_clas[keep]\n",
    "        \n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        gt_clas = gt_clas - 1 # the databunch add a 'background' class to classes[0], but we don't want that,so gt_clas-1\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        pred_clas = pred_clas[idx]\n",
    "        pred_clas = pred_clas.max(1)[1]\n",
    "        \n",
    "        posCnt += (pred_clas==gt_clas).sum().item()\n",
    "        totCnt += gt_clas.shape[0]\n",
    "\n",
    "    return posCnt/totCnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox center difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def cent_d(pred_batch, *gt_batch, gaf):\n",
    "    dif = tensor(0.)\n",
    "    cnt = tensor(0.)\n",
    "    for pred_txy,pred_thw,gt_bboxs,_ in zip(pred_batch[0],pred_batch[3], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "          \n",
    "        pred_t = torch.cat([pred_txy,pred_thw],dim=1)\n",
    "        \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        pred_t = pred_t[idx]\n",
    "        pred_c = bbox2chw(gaf.t2b(pred_t,idx))[...,:2]\n",
    "        gt_c = bbox2chw(gt_bboxs)[...,:2]\n",
    "        \n",
    "        tmp = (gt_c - pred_c).abs().sum()\n",
    "        dif += tmp\n",
    "        cnt += len(idx)\n",
    "    \n",
    "    return dif/cnt/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox height and width ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hw_r(pred_batch, *gt_batch, gaf):\n",
    "    logR = tensor(0.)\n",
    "    cnt = tensor(0.)\n",
    "    for pred_txy,pred_thw,gt_bboxs,_ in zip(pred_batch[0],pred_batch[3], *gt_batch):\n",
    "        keep = get_y(gt_bboxs)\n",
    "        if keep.numel()==0: continue\n",
    "          \n",
    "        pred_t = torch.cat([pred_txy,pred_thw],dim=1)\n",
    "        \n",
    "        gt_bboxs = gt_bboxs[keep]\n",
    "        gt_bboxs = (gt_bboxs + 1) / 2\n",
    "        \n",
    "        scores,hits = gaf.get_scores_hits(gt_bboxs)\n",
    "        idx = idx_fromScoresHits(scores,hits)\n",
    "        \n",
    "        pred_t = pred_t[idx]\n",
    "        pred_hw = bbox2chw(gaf.t2b(pred_t,idx))[...,2:]\n",
    "        gt_hw = bbox2chw(gt_bboxs)[...,2:]\n",
    "        \n",
    "        tmp = (pred_hw/gt_hw).log().abs().sum()\n",
    "        logR += tmp\n",
    "        cnt += len(idx)\n",
    "    \n",
    "    return (logR/(cnt*2)).exp() # *2是因为每个bbox有h和w，h和w的贡献在logR中被加在一起了，而cnt仅是对bbox的计数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_acc(pred,*y,gaf=gaf), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clas = len(data.train_ds.y.classes)-1\n",
    "print(1/n_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox center difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent_d(pred,*y,gaf=gaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((0.5/49)*49*49+(0.5/25)*25*25+(0.5/13)*13*13)/(49*49+25*25+13*13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox height and width ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_r(pred,*y,gaf=gaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个值是否合理？ \n",
    "\n",
    "下面我仅考虑高度 h 来分析，宽度 w 与之是同样的情况。  \n",
    "  \n",
    "根据定义，$b_h=p_h\\cdot e^{t_h}$，即 $log(\\frac{b_h}{p_h})=t_h$，其中 $t_h$ 是初始化模型的输出，属于标准正态分布。  \n",
    "  \n",
    "其中 $p_h$ 是 anchor 高度，因为我们在设计 anchor 时选择了 $p_h$ 位于 $o_h$（表示anchor所负责的那部分目标框的宽度）的分布的中心（对数坐标下），即$log(\\frac{o_h}{p_h})$是均值为0的随机分布，我们假设这个随机分布也是正态分布，标准差为$\\sigma_o$（小于1，因为我们设计 anchor 时，它所负责的目标框的宽度的范围约为\\[-1.4,+1.4\\]（对数坐标），那么可以粗略估计其标准差在0.5左右）。从正太分布的对称性上看，$log(\\frac{p_h}{o_h})=-log(\\frac{o_h}{p_h})$属于同样的分布。\n",
    "\n",
    "则$log(\\frac{b_h}{o_h})=log(\\frac{b_h}{p_h})+log(\\frac{p_h}{o_h})$应是均值为0，标准差为$\\sqrt{1+\\sigma_o^2}\\approx\\sqrt{1.25}\\approx1.1$的正态分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们令 $a=log(\\frac{b_h}{o_h})$ 属于 $N(0,1.1)$，下面生成随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.normal(0,1.1,size=(1,1000)).squeeze()\n",
    "a.mean(), a.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对照代码，我们生成的 a 对应 `(pred_hw/gt_hw).log()` 部分，所以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logR = a.abs().sum()\n",
    "logR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我们这里仅考虑了 h，所以相当于 `cnt` 不需要 `*2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(logR/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到的值与调用`hw_r()`的结果是接近的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted anchors_loss_metrics.ipynb to exp/nb_anchors_loss_metrics.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py --fname 'anchors_loss_metrics.ipynb' --outputDir './exp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
