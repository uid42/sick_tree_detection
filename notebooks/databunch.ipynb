{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core import debugger as idb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#from FLAI.detect_symbol.exp import databunch as databunch_detsym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.vision.data import ObjectCategoryProcessor, _get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.vision.image import _draw_rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "pat_coord = re.compile(r'\\d+')\n",
    "#图片在data_root目录下面的image目录里面，数字命名。\n",
    "pat_imgName = re.compile(r'(\\w+/\\d+\\.jpg)$')\n",
    "pat_clas = re.compile(r'\\w+')\n",
    "pat_num = re.compile(r'\\d+')    \n",
    "\n",
    "def get_label_from_df(fn, df, pat_imgName, coord_col, cat_col, asbbox = False):\n",
    "    '''\n",
    "    fn: \n",
    "        file path.\n",
    "    df: \n",
    "        a dataframe stores all the label information, imageName shoud be as index.\n",
    "    repat_imgName: \n",
    "        a regular expression pattern, used to find the imageName from fn, where imageName is stored in df \n",
    "    box_col:\n",
    "        the column name of bounding boxs\n",
    "    cat_col:\n",
    "        the column name of categories\n",
    "    '''\n",
    "    #print('glfd:', type(fn), fn)    \n",
    "    fn = pat_imgName.findall(str(fn))[0]\n",
    "    coords = df.loc[fn,coord_col]\n",
    "    coords = pat_num.findall(coords)\n",
    "    coords = list(map(np.long, coords))\n",
    "    coords = np.array(coords).reshape(-1, 2) * 1.0\n",
    "    coords = coords.tolist()\n",
    "    \n",
    "    if asbbox:#暂时还沿用之前的bbox的形式。\n",
    "        #import pdb;pdb.set_trace()\n",
    "        ncoords = []\n",
    "        for c in coords:\n",
    "            ncoords += [[c[0], c[1], c[0] + 1, c[1] + 1]]\n",
    "        coords = ncoords\n",
    "    \n",
    "    cats = df.loc[fn,cat_col]\n",
    "    cats = pat_clas.findall(cats)\n",
    "    #if fn.find('00000') >= 0:\n",
    "    #    print('get_label_from_df', coords, cats, asbbox)\n",
    "        \n",
    "    return (coords, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_label_from_df_points(fn, df, pat_imgName, coord_col, cat_col):\n",
    "    '''\n",
    "    fn: \n",
    "        file path.\n",
    "    df: \n",
    "        a dataframe stores all the label information, imageName shoud be as index.\n",
    "    repat_imgName: \n",
    "        a regular expression pattern, used to find the imageName from fn, where imageName is stored in df \n",
    "    box_col:\n",
    "        the column name of bounding boxs\n",
    "    cat_col:\n",
    "        the column name of categories\n",
    "    '''\n",
    "    fn = pat_imgName.findall(str(fn))[0]\n",
    "    coords = df.loc[fn,coord_col]\n",
    "    coords = pat_num.findall(coords)\n",
    "    coords = list(map(np.long, coords))\n",
    "    coords = np.array(coords).reshape(-1, 2) * 1.0    \n",
    "    coords = coords.tolist()    \n",
    "    cats = df.loc[fn,cat_col]\n",
    "    cats = pat_clas.findall(cats)\n",
    "     \n",
    "    #print('ctre', coords[0])\n",
    "    return Tensor(coords[0])\n",
    "    #return Tensor(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# 只能返回一个点的列表\n",
    "def get_databunch_points(data_root='./ds_20200818'\n",
    "        , csv_name='gends.csv', valid_pct=0.2, bs=64, device=torch.device('cpu'), cache=False):\n",
    "    '''\n",
    "    --------------------------------\n",
    "    参数：\n",
    "    -- data_root：数据集的总目录\n",
    "    -- img_path: 图片目录\n",
    "    -- csv_name：存放标注信息的csv文件名，其要符合“对csv的要求”\n",
    "    -- valid_pct：随机分割训练/验证集，该参数指定验证集的比例\n",
    "    -- bs：batch size\n",
    "    -- device：在datalaoder迭代时，dataloader先将batch加载到该device，做batch transform，然后返回。\n",
    "    -- cache：dataset是否将所有图片预缓存入内存\n",
    "    --------------------------------\n",
    "    返回值：\n",
    "    -- 一个databunch对象\n",
    "    --------------------------------\n",
    "    对csv的要求：\n",
    "    1，带index\n",
    "    2，存放图片名的列名称为\"image\"\n",
    "    3，存放位置信息信息的列名称为\"coord\"\n",
    "    4，存放类别信息的列名称为\"clas\"\n",
    "    --------------------------------\n",
    "    '''\n",
    "    data_root = Path(data_root)\n",
    "    csv_name = Path('gends.csv')\n",
    "    # 读入csv，稍作处理，方便get_label函数操作\n",
    "    csv_path = data_root/csv_name\n",
    "    df = pd.read_csv(csv_path,index_col=0)\n",
    "    df = df.set_index('image')\n",
    "\n",
    "    data = PointsItemList.from_folder(data_root).split_by_rand_pct(valid_pct = valid_pct)\n",
    "    func = partial(get_label_from_df_points, df=df, pat_imgName=pat_imgName\n",
    "                   , coord_col='coord', cat_col='clas')\n",
    "    #import pdb;pdb.set_trace();\n",
    "    data = data.label_from_func(func=func)\n",
    "    \n",
    "    data = data.databunch(bs=bs, device=device)\n",
    "    data = data.normalize(imagenet_stats)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    # 缓存图片\n",
    "    if cache:\n",
    "        data.cache_ds_img()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageLPts(ImagePoints):\n",
    "    \"在图片上标注带类别的点。修改自ImageBBox。\"\n",
    "    def __init__(self, flow:FlowField, scale:bool=True, y_first:bool=True, labels:Collection=None,\n",
    "                 classes:dict=None, pad_idx:int=0):\n",
    "        super().__init__(flow, scale, y_first)\n",
    "        self.pad_idx = pad_idx\n",
    "        if labels is not None and len(labels)>0 and not isinstance(labels[0],Category):\n",
    "            labels = array([Category(l,classes[l]) for l in labels])\n",
    "        self.labels = labels\n",
    "\n",
    "    def clone(self) -> 'ImageLPts':\n",
    "        \"Mimic the behavior of torch.clone for `Image` objects.\"\n",
    "        flow = FlowField(self.size, self.flow.flow.clone())\n",
    "        return self.__class__(flow, scale=False, y_first=False, labels=self.labels, pad_idx=self.pad_idx)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, h:int, w:int, pts:Collection[Collection[int]], labels:Collection=None, classes:dict=None,\n",
    "               pad_idx:int=0, scale:bool=True)->'ImageLPts':\n",
    "        \"Create an ImageLPts object from points and labels.\"\n",
    "        #应对没有目标的情况\n",
    "        if isinstance(pts,list) and len(pts)==0:\n",
    "            pts = [[0,0]]\n",
    "            labels = [0]\n",
    "            \n",
    "        if isinstance(pts, np.ndarray) and pts.dtype == np.object: pts = np.array([bb for bb in pts])\n",
    "        pts = tensor(pts).float()        \n",
    "        flow = FlowField((h,w), pts)#.view(-1,2))\n",
    "        return cls(flow, labels=labels, classes=classes, pad_idx=pad_idx, y_first=True, scale=scale)\n",
    "\n",
    "    @property\n",
    "    def data(self)->Union[FloatTensor, Tuple[FloatTensor,LongTensor]]:\n",
    "        #import pdb;pdb.set_trace()\n",
    "        #pts = self.flow.flow.flip(1).view(-1, 2, 2).contiguous().clamp(min=-1, max=1)\n",
    "        pts = self.flow.flow.flip(1).contiguous().clamp(min=-1, max=1)\n",
    "        \n",
    "        lbls = np.array([o.data for o in self.labels]) if self.labels is not None else None\n",
    "        return pts if lbls is None else (pts, lbls)\n",
    "\n",
    "    def show(self, y:Image=None, ax:plt.Axes=None, figsize:tuple=(3,3), title:Optional[str]=None, hide_axis:bool=True,\n",
    "        color:str='white', **kwargs):\n",
    "        \"Show the `ImageLPts` on `ax`.\"\n",
    "        if ax is None: _,ax = plt.subplots(figsize=figsize)\n",
    "        pts = self.flow.flow.flip(1).contiguous().clamp(min=-1, max=1)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        lbls = np.array([o.data for o in self.labels]) if self.labels is not None else None\n",
    "        h,w = self.flow.size\n",
    "        pts.add_(1).mul_(torch.tensor([h/2, w/2])).long()\n",
    "        for i, pt in enumerate(pts):\n",
    "            if lbls is not None: text = str(lbls[i])\n",
    "            else: text=None\n",
    "            #print('draw:', pt)\n",
    "            text = None #反正没有别的东西了。不需要显示文字\n",
    "            _draw_rect(ax, np.array([pt[1],pt[0], 5, 5]), text=text, color=color)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#修改自bb_pad_collate\n",
    "def ptslbl_pad_collate(samples:BatchSamples, pad_idx:int=0) -> Tuple[FloatTensor, Tuple[LongTensor, LongTensor]]:\n",
    "    \"Function that collect `samples` of labelled points and adds padding with `pad_idx`.\"\n",
    "    if isinstance(samples[0][1], int): return data_collate(samples)\n",
    "    max_len = max([len(s[1].data[1]) for s in samples])\n",
    "    pts = torch.zeros(len(samples), max_len, 2)\n",
    "    labels = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    imgs = []\n",
    "    for i,s in enumerate(samples):\n",
    "        imgs.append(s[0].data[None])\n",
    "        tpts, lbls = s[1].data\n",
    "        if not (tpts.nelement() == 0):\n",
    "            pts[i,-len(lbls):] = tpts\n",
    "            labels[i,-len(lbls):] = tensor(lbls)\n",
    "    return torch.cat(imgs,0), (pts,labels)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ObjectCategoryList_PtLbl(MultiCategoryList):\n",
    "    \"`ItemList` for labelled points.\"\n",
    "    _processor = ObjectCategoryProcessor\n",
    "    \n",
    "    def get(self, i):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        return ImageLPts.create(*_get_size(self.x,i), *self.items[i], classes=self.classes, pad_idx=self.pad_idx)\n",
    "    \n",
    "    def analyze_pred(self, pred): return pred\n",
    "\n",
    "    def reconstruct(self, t, x):\n",
    "        (bboxes, labels) = t\n",
    "        if len((labels - self.pad_idx).nonzero()) == 0: return\n",
    "        i = (labels - self.pad_idx).nonzero().min()\n",
    "        bboxes,labels = bboxes[i:],labels[i:]\n",
    "        return ImageLPts.create(*x.size, bboxes, labels=labels, classes=self.classes, scale=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ObjectItemList_PtLbl(ImageList):\n",
    "    \"`ItemList` suitable for object detection.\"\n",
    "    _label_cls,_square_show_res = ObjectCategoryList_PtLbl,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# 这个函数是为了在其它模块的设计时快速构造databunch\n",
    "def get_databunch(data_root='./ds_20200818'\n",
    "        , csv_name='gends.csv', valid_pct=0.2, bs=64, device=torch.device('cpu'), cache=False):\n",
    "    '''\n",
    "    --------------------------------\n",
    "    参数：\n",
    "    -- data_root：数据集的总目录\n",
    "    -- img_path: 图片目录\n",
    "    -- csv_name：存放标注信息的csv文件名，其要符合“对csv的要求”\n",
    "    -- valid_pct：随机分割训练/验证集，该参数指定验证集的比例\n",
    "    -- bs：batch size\n",
    "    -- device：在datalaoder迭代时，dataloader先将batch加载到该device，做batch transform，然后返回。\n",
    "    -- cache：dataset是否将所有图片预缓存入内存\n",
    "    --------------------------------\n",
    "    返回值：\n",
    "    -- 一个databunch对象\n",
    "    --------------------------------\n",
    "    对csv的要求：\n",
    "    1，带index\n",
    "    2，存放图片名的列名称为\"image\"\n",
    "    3，存放位置信息信息的列名称为\"coord\"\n",
    "    4，存放类别信息的列名称为\"clas\"\n",
    "    --------------------------------\n",
    "    '''\n",
    "    data_root = Path(data_root)\n",
    "    csv_name = Path('gends.csv')\n",
    "    # 读入csv，稍作处理，方便get_label函数操作\n",
    "    csv_path = data_root/csv_name\n",
    "    df = pd.read_csv(csv_path,index_col=0)\n",
    "    df = df.set_index('image')\n",
    "\n",
    "    # ItemList\n",
    "    data = ObjectItemList_PtLbl.from_csv(path=data_root, csv_name=csv_name\n",
    "                                   , cols='image')    \n",
    "\n",
    "    # split ItemList to get ItemLists\n",
    "    data = data.split_by_rand_pct(valid_pct=valid_pct)\n",
    "\n",
    "    # label ItemLists to get LabelLists\n",
    "    func = partial(get_label_from_df, df=df, pat_imgName=pat_imgName\n",
    "                   , coord_col='coord', cat_col='clas', asbbox = False)\n",
    "    data = data.label_from_func(func=func)\n",
    "\n",
    "    # add transforms\n",
    "#     trn_tfms = [*zoom_crop(scale=(0.9,1.1),do_rand=True,p=1),\n",
    "#                 rot90_affine(use_on_y=True)]\n",
    "#     val_tfms = []\n",
    "#    data = data.transform(tfms=[trn_tfms,val_tfms], tfm_y=True, remove_out=True)\n",
    "    # create DataBunch from LabelLists\n",
    "    data = data.databunch(bs=bs, device=device, collate_fn=ptslbl_pad_collate, num_workers=0)\n",
    "\n",
    "    # normalize\n",
    "    data = data.normalize()\n",
    "    \n",
    "    # 缓存图片\n",
    "    if cache:\n",
    "        data.cache_ds_img()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做些设置\n",
    "data_root = './ds_20200818/'\n",
    "data_root = Path(data_root)\n",
    "\n",
    "csv_name = 'gends.csv'\n",
    "csv_path = data_root/csv_name\n",
    "\n",
    "img_subpath = 'image'\n",
    "img_path = data_root/img_subpath\n",
    "\n",
    "bs = 64\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入csv，稍作处理，方便get_label函数操作\n",
    "df = pd.read_csv(csv_path,index_col=0)\n",
    "df = df.set_index('image')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试一下ObjectItemList_PtLbl\n",
    "data = ObjectItemList_PtLbl.from_csv(path=data_root, csv_name=csv_name\n",
    "                               , cols='image')\n",
    "# split ItemList to get ItemLists\n",
    "data = data.split_by_rand_pct(valid_pct=0.2)\n",
    "# label ItemLists to get LabelLists\n",
    "func = partial(get_label_from_df, df=df, pat_imgName=pat_imgName\n",
    "               , coord_col='coord', cat_col='clas', asbbox = False)\n",
    "data = data.label_from_func(func=func)\n",
    "# add transforms\n",
    "#     trn_tfms = [*zoom_crop(scale=(0.9,1.1),do_rand=True,p=1),\n",
    "#                 rot90_affine(use_on_y=True)]\n",
    "#     val_tfms = []\n",
    "#    data = data.transform(tfms=[trn_tfms,val_tfms], tfm_y=True, remove_out=True)\n",
    "# create DataBunch from LabelLists\n",
    "\n",
    "#data = data.databunch(bs=bs, device=device, collate_fn=bb_pad_collate, num_workers=0)\n",
    "data = data.databunch(bs=bs, device=device, collate_fn=ptslbl_pad_collate, num_workers=0)\n",
    "\n",
    "# normalize\n",
    "data = data.normalize()\n",
    "data.show_batch(rows = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_databunch_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs.BIWI_HEAD_POSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add transforms\n",
    "# trn_tfms = [*zoom_crop(scale=(0.9,1.1),do_rand=True,p=1),\n",
    "#             rot90_affine(use_on_y=True)]\n",
    "# val_tfms = []\n",
    "\n",
    "# data = data.transform(tfms=[trn_tfms,val_tfms], tfm_y=True, remove_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看统计信息\n",
    "#databunch_detsym.databunch_statistics(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lesson3-head-pose.ipynb\n",
    "data = PointsItemList.from_folder('./ds_20200818/image').split_by_rand_pct(valid_pct = 0.2)\n",
    "func = partial(get_label_from_df, df=df, pat_imgName=pat_imgName\n",
    "                   , coord_col='coord', cat_col='clas')\n",
    "data = data.label_from_func(func=func)\n",
    "\n",
    "data = data.databunch(bs=8, device=device, collate_fn=bb_pad_collate)\n",
    "data = data.normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted databunch.ipynb to ../exp/databunch.py\r\n"
     ]
    }
   ],
   "source": [
    "!python ../notebook2script.py --fname 'databunch.ipynb' --outputDir '../exp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
