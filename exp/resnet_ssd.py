
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/resnet_ssd.ipynb

#================================================
import torchvision


#================================================
from torch import nn


#================================================
import torch


#================================================
import torchvision


#================================================
from collections import OrderedDict


#================================================
from IPython.core import debugger as idb


#================================================
from torchvision.models.resnet import conv1x1


#================================================
from FLAI.detect_symbol.exp import resnet_ssd as resnet_ssd_detsym


#================================================
class ssd_block(nn.Module):
    '''
    和detect_symbol里面的ssd_block相比只是去掉了宽高相关的部分
    '''
    def __init__(self, k, nin, n_clas):
        '''
        ssd头模块，它根据某层的特征图给出bbox预测信息，该模块的输出包含4个部分：
        -- loc：bbox中心偏移，2个值
        -- conf：目标信心，1个值
        -- clas：目标类别，n_clas个值
        ----------------------------------------
        参数：
        -- k：每个grid的anchor数
        -- nin：输入特征图通道数
        -- n_clas：目标类别数
        '''
        super().__init__()
        self.k = k
        self.oconv_loc = nn.Conv2d(nin, 2*k, 3, padding=1) # bbox center
        self.oconv_conf = nn.Conv2d(nin, 1*k, 3, padding=1) # confidence
        self.oconv_clas = nn.Conv2d(nin, n_clas*k, 3, padding=1) # classification

    def forward(self, x):
        return (resnet_ssd_detsym.flatten_grid_anchor(self.oconv_loc(x), self.k),
                resnet_ssd_detsym.flatten_grid_anchor(self.oconv_conf(x), self.k),
                resnet_ssd_detsym.flatten_grid_anchor(self.oconv_clas(x), self.k)
               )


#================================================
class ResNetIsh_SSD(resnet_ssd_detsym.ResNetIsh_SSD):
    def forward(self, x):
        outs = self._forward_impl(x)

        locs,confs,clss = [],[],[]
        for out in outs:
            locs += [out[0]]
            confs += [out[1]]
            clss += [out[2]]

        return (torch.cat(locs,dim=1),
                torch.cat(confs,dim=1),
                torch.cat(clss,dim=1)
               )


#================================================
class ResNetIsh_1SSD(resnet_ssd_detsym.ResNetIsh_1SSD):
    def forward(self, x):
        outs = self._forward_impl(x)

        locs,confs,clss = [],[],[]
        for out in outs:
            locs += [out[0]]
            confs += [out[1]]
            clss += [out[2]]

        return (torch.cat(locs,dim=1),
                torch.cat(confs,dim=1),
                torch.cat(clss,dim=1)
               )


#================================================
class ResNetIsh_1SSD_fpn(ResNetIsh_1SSD):
    '''
    带fpn的
    '''
    def init_fpn(self):
        assert len(self.pred_layerIds) > 1
        #这个现在固定的就是resnet18用的
        self.fpn = torchvision.ops.FeaturePyramidNetwork([256, 512, 1024], 256)

    def _forward_impl(self, x):
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        outs = []
        input4fpn = OrderedDict()
        for i in range(len(self.res_blocks)):
            x = self.res_blocks[i](x)
            if i in self.pred_layerIds:
                #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#                 outs += [self.neck_blocks[i-self.pred_layerIds[0]](x)]
                ################################
                if self.fpn is None:#没有fpn，直接用neck_block
                    neck_out = self.neck_blocks[i-self.pred_layerIds[0]](x)
                    outs += [self.head_block(neck_out)]
                else:#如果有fpn跳过neck_block
                    key = 'feat%d' % (i-self.pred_layerIds[0])
                    input4fpn[key] = x
                #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
        if self.fpn is not None:
            fpnout = self.fpn(input4fpn)
            #先只取最终合并完成的那个特征图。这个和之前的只用一层的特征图的行为是一致的
            outs += [self.head_block(fpnout['feat0'])]

        return outs




#================================================
def get_resnet18_1ssd(layers4fpn = False, num_classes = 1):
    #layers4fpn是否保留后面的两层给fpn用
    if not layers4fpn:
        return ResNetIsh_1SSD(block=torchvision.models.resnet.BasicBlock,
                   layers=[2,2,2],
                   chs=[64,128,256],
                   strides=[1,2,2],
                   pred_layerIds=[2],
                   num_anchors=1,
                   neck_block=resnet_ssd_detsym.cnv1x1_bn_relu,
                   head_chin=256,
                   head_block=ssd_block,
                   num_classes=num_classes)
    else:
        return ResNetIsh_1SSD(block=torchvision.models.resnet.BasicBlock,
                   layers=[2,2,2,2,2],
                   chs=[64,128,256,512,1024],
                   strides=[1,2,2,2,2],
                   pred_layerIds=[2, 3, 4],
                   num_anchors=1,
                   neck_block=resnet_ssd_detsym.cnv1x1_bn_relu,
                   head_chin=256,
                   head_block=ssd_block,
                   num_classes=num_classes)


#================================================
def get_resnet18_ssd(layers4fpn = False, num_classes = 1):
    if not layers4fpn:
        return ResNetIsh_SSD(block=torchvision.models.resnet.BasicBlock,
                  layers=[2,2,2],
                  chs=[64,128,256],
                  strides=[1,2,2],
                  pred_layerIds=[2],
                  num_anchors=[1],
                  pred_block=ssd_block,
                  num_classes=num_classes)
    else:
        return ResNetIsh_SSD(block=torchvision.models.resnet.BasicBlock,
                  layers=[2,2,2,2,2],
                  chs=[64,128,256,512,1024],
                  strides=[1,2,2,2,2],
                  pred_layerIds=[2, 3, 4],
                  num_anchors=[1, 1, 1],
                  pred_block=ssd_block,
                  num_classes=num_classes)
