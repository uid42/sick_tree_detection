
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/train_script_logger.ipynb

#================================================
from fastai.basic_train import LearnerCallback


#================================================
from fastai.callbacks.general_sched import *
from fastai.callback import *


#================================================
from fastai.core import *


#================================================
from IPython.core import debugger as idb


#================================================
from FLAI.detect_symbol.exp import databunch
from FLAI.detect_symbol.exp import resnet_ssd as resnet_ssd_detsym
from FLAI.detect_symbol.exp import init_model as init_model_detsym
from FLAI.detect_symbol.exp import anchors_loss_metrics as anchors_loss_metrics_detsym
from FLAI.detect_symbol.exp import optimizer as optimizer_detsym
from FLAI.detect_symbol.exp import tensorboard_callback as tensorboard_callback_detsym
from FLAI.detect_symbol.exp import scheduling_train as scheduling_train_detsym


#================================================
import sys
if '..' not in sys.path:
    sys.path.append('..')
from exp import resnet_ssd
from exp import anchors_loss_metrics
from exp import init_model


#================================================
import torch


#================================================
from torch import tensor


#================================================
from torch import nn


#================================================
from torch.nn import Sequential, ModuleList


#================================================
from fastai.basic_train import Learner


#================================================
from fastai.torch_core import bn_types,bias_types


#================================================
from functools import partial


#================================================
import os,shutil


#================================================
from fastai.callbacks import CSVLogger


#================================================
from fastai.callbacks.tracker import SaveModelCallback


#================================================
def txt_write(fh, i, opt, lr, path, csv_fname):
    fh.write('===================================\n')
    fh.write(f'run_{i}\n')
    fh.write('-----------------------------------\n')
    fh.write(f'--opt_func: {opt}\n')
    fh.write(f'--lr: {lr}\n')
    fh.write(f'--csv_log: {path}/{csv_fname}.csv\n')
    fh.write(f'--best model: {path}/models/run_{i}.pth\n')


#================================================
def multi_train(get_learn, epoch_len, epochs, opts, lrs, checkpoints, tb_log_root,autoSave=True):
    '''
    可以从checkpoint继续训练，为了保证训练连续性，需要手动设置lr与checkpoint保存时一致。
    '''
    # 清理tensorboard log dir
    if os.path.exists(tb_log_root): shutil.rmtree(tb_log_root)
    os.mkdir(tb_log_root)

    if not os.path.exists('./run_log/'): os.mkdir('./run_log/')
    txtlog = open('./run_log/log.txt',mode='w')
    for i,(opt,lr,checkpoint) in enumerate(zip(opts,lrs,checkpoints)):
        # create a learner
        learn = get_learn()

        # set optimizer
        learn.opt_func = opt

        # load checkpoint
        if checkpoint is not None:
            with open(checkpoint,'rb') as f:
                learn.load(f)

        # 在txt log中记录
        csv_log_dir = f'csv_log/'
        if not os.path.exists(learn.path/csv_log_dir): os.mkdir(learn.path/csv_log_dir)
        csv_fname = csv_log_dir+f'run_{i}'
        txt_write(txtlog,i,opt,lr,learn.path,csv_fname)

        callbacks = []
        # get csvlogger callback
        csvLog = CSVLogger(learn,filename=csv_fname)
        callbacks += [csvLog]

        if autoSave:
            # savemodel callback
            autoSave = SaveModelCallback(learn,monitor='valid_loss',mode='min',every='improvement',name=f'run_{i}')
            callbacks += [autoSave]

        # get tensorboard callback
        tbCb = get_tbCb(learn,tb_log_root+f'run_{i}')
        callbacks += [tbCb]

        # train
        fit(learn=learn, epoch_len=epoch_len, epochs=epochs, lr=lr, callbacks=callbacks)

    txtlog.close()


#================================================
# 设置device
device = torch.device('cuda')



#================================================
device_ids = [0]


#================================================
def split_model(model):
#     idb.set_trace()
    group0 = ModuleList()
    group1 = ModuleList()

    pretrained_layers = Sequential(model.conv1, model.bn1, model.res_blocks[:4])
#     noPretrain_layers = Sequential(model.res_blocks[4], model.neck_blocks, model.head_block)
    noPretrain_layers = Sequential(model.neck_blocks, model.head_block)

    #把pretrained layers分作batchnorm部分（放在group1），和非batchnorm部分（放在group0）
    for m in pretrained_layers.modules():
        if isinstance(m,bn_types): group1.append(m)
        elif isinstance(m,bias_types): group0.append(m)

    #把非pretrain的层放到group1
    for m in noPretrain_layers.children():
        group1.append(m)

    return [group0, group1]


#================================================
clas_cnts = [11191, 712, 1362, 224, 8710, 1212, 1139, 8686, 857, 2176, 6175, 1869, 14794, 1435, 13628, 9618, 1462]
weights = anchors_loss_metrics_detsym.get_clasWeights(clas_cnts,10)
weights = tensor(weights).float().to(device)
# weights = None


#================================================
def get_learn_detectsym_17clas(data,gaf,clas_weights=weights):
    '''
    用的符号检测的17个类别的数据集
    '''
    # create model
    model = resnet_ssd.get_resnet18_1ssd(num_classes = 17)
    model.load_state_dict(torch.load('./models/pretrained_res18_1ssd.pth'));

    # create learner
    learn = Learner(data,model)

    # split model
    learn.layer_groups = split_model(learn.model)

    # set multi-gpu
    if data.device.type=='cuda':
        learn.model = torch.nn.DataParallel(learn.model,device_ids=device_ids)#device_ids=[0,1,2,3,4,5])

    # set loss func
    learn.loss_func = partial(anchors_loss_metrics.yolo_L, gaf=gaf, conf_th=1, clas_weights=clas_weights, lambda_nconf=10)

    # 添加metrics
    learn.metrics += [partial(anchors_loss_metrics.clas_L,   gaf=gaf, clas_weights=clas_weights)]
    learn.metrics += [partial(anchors_loss_metrics.cent_L,   gaf=gaf, clas_weights=clas_weights)]
    learn.metrics += [partial(anchors_loss_metrics.pConf_L,  gaf=gaf, clas_weights=clas_weights)]
    learn.metrics += [partial(anchors_loss_metrics.nConf_L,  gaf=gaf, conf_th=1)]
    learn.metrics += [partial(anchors_loss_metrics.clas_acc, gaf=gaf)]
    learn.metrics += [partial(anchors_loss_metrics.cent_d,   gaf=gaf)]

    return learn


#================================================
def get_tbCb(learn,log_dir):
    tbCb = tensorboard_callback_detsym.TensorBoardCallback(
                                   learn=learn,
                                   log_dir=log_dir,
                                   plot_net=False,
                                   plot_loss=True,
                                   metric_plots=[],
                                   hyper_plots=['lr'],
                                   hist_plots=['res_blocks.2.0.conv1.weight',
                                               'neck_blocks.0.pwConv.weight'],
                                   hist_iters=50)
    return tbCb


#================================================
def fit(learn,epoch_len,epochs,lr,callbacks):
    scheduling_train_detsym.fit_with_warmup_multiAnnealPlat(learn,
                                    epoch_len=epoch_len,
                                    num_epoch=epochs,

                                    lr_start=lr/10,
                                    lr_constant=lr,
                                    warmup_iter=10,

                                    monitor='train_smooth',
                                    worseN_thres=5,
                                    annealRate=10,
                                    duration_thres=30,
                                    annealIte=10,
                                    phaseMaxN=3,
                                    finetune_stop=1,
                                    callbacks=callbacks)


#================================================
# get databunch
data = databunch.get_databunch(data_root = '../../detect_symbol/data/ds_20200429', bs=16, device=device)


#================================================
# grid anchor functions
gaf = anchors_loss_metrics.GridAnchor_Funcs(fig_hw = (776,776)
                         , grids = [(49,49)]
                         , device = device)
gvs, avs = gaf.gvs, gaf.avs


#================================================
opts = [partial(optimizer_detsym.Adam, betas=(0.9,0.99))]

lrs = [1e-3]

checkpoints = [None]


#================================================
multi_train(get_learn=partial(get_learn_detectsym_17clas,data=data,gaf=gaf),
            epoch_len=1e9, epochs=500,
            opts=opts, lrs=lrs, checkpoints=checkpoints,
            tb_log_root='./tb_log/',
            autoSave=True)
